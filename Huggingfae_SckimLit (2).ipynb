{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fZBDXFutfpG2"
      },
      "source": [
        "# Install dependencies  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "AAcs3EwlPQRz",
        "outputId": "36501fe1-3d3f-4495-df47-02b36a5f8900"
      },
      "outputs": [],
      "source": [
        "\n",
        "try:\n",
        "  import datasets, evaluate, accelerate\n",
        "  import gradio as gr\n",
        "except ModuleNotFoundError:\n",
        "  !pip install -U datasets evaluate accelerate gradio\n",
        "  import datasets, evaluate, accelerate\n",
        "  import gradio as gr\n",
        "\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import transformers\n",
        "\n",
        "print(f\"Using transformers version: {transformers.__version__}\")\n",
        "print(f\"Using datasets version: {datasets.__version__}\")\n",
        "print(f\"Using torch version: {torch.__version__}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eo-jZYv4gfsS"
      },
      "source": [
        "# Loading Dataset(PubMed_20k_RCT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lWewSBaiytPb"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/Franck-Dernoncourt/pubmed-rct\n",
        "!ls pubmed-rct"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uA3_rlYJ0Bfe"
      },
      "outputs": [],
      "source": [
        "!ls pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wMNHNoze0Fox"
      },
      "outputs": [],
      "source": [
        "data_dir=\"pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PHknt2ue0KqX"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "filenames=[data_dir+filename for filename in os.listdir(data_dir)]\n",
        "filenames"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wQvi3awJ0Npi"
      },
      "outputs": [],
      "source": [
        "# creating a function that read filename and returns the lines of text as a line\n",
        "def read_file(filename):\n",
        "  with open(filename,\"r\") as f:\n",
        "    lines=f.readlines()\n",
        "  return lines\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-3sPTKME0TUp"
      },
      "outputs": [],
      "source": [
        "train_lines=read_file(data_dir+\"train.txt\")\n",
        "train_lines[:20]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mK0trTMK0WrC"
      },
      "outputs": [],
      "source": [
        "len(train_lines)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JVgtZ5SifytC"
      },
      "source": [
        "# Preprocessing function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gkLd-BEMjWDV"
      },
      "outputs": [],
      "source": [
        "def preprocess_text_with_line_numbers(filename):\n",
        "  \"\"\"Returns a list of dictionaries of abstract line data.\n",
        "\n",
        "  Takes in filename, reads its contents and sorts through each line,\n",
        "  extracting things like the target label, the text of the sentence,\n",
        "  how many sentences are in the current abstract and what sentence number\n",
        "  the target line is.\n",
        "\n",
        "  Args:\n",
        "      filename: a string of the target text file to read and extract line data\n",
        "      from.\n",
        "\n",
        "  Returns:\n",
        "      A list of dictionaries each containing a line from an abstract,\n",
        "      the lines label, the lines position in the abstract and the total number\n",
        "      of lines in the abstract where the line is from. For example:\n",
        "\n",
        "      [{\"target\": 'CONCLUSION',\n",
        "        \"text\": The study couldn't have gone better, turns out people are kinder than you think\",\n",
        "        \"line_number\": 8,\n",
        "        \"total_lines\": 8}]\n",
        "  \"\"\"\n",
        "  input_lines = read_file(filename) # get all lines from filename\n",
        "  abstract_lines = \"\" # create an empty abstract\n",
        "  abstract_samples = [] # create an empty list of abstracts\n",
        "\n",
        "  # Loop through each line in target file\n",
        "  for line in input_lines:\n",
        "    if line.startswith(\"###\"): # check to see if line is an ID line\n",
        "      abstract_id = line\n",
        "      abstract_lines = \"\" # reset abstract string\n",
        "    elif line.isspace(): # check to see if line is a new line\n",
        "      abstract_line_split = abstract_lines.splitlines() # split abstract into separate lines\n",
        "\n",
        "      # Iterate through each line in abstract and count them at the same time\n",
        "      for abstract_line_number, abstract_line in enumerate(abstract_line_split):\n",
        "        line_data = {} # create empty dict to store data from line\n",
        "        target_text_split = abstract_line.split(\"\\t\") # split target label from text\n",
        "        line_data[\"target\"] = target_text_split[0] # get target label\n",
        "        line_data[\"text\"] = target_text_split[1].lower() # get target text and lower it\n",
        "        line_data[\"line_number\"] = abstract_line_number # what number line does the line appear in the abstract?\n",
        "        line_data[\"total_lines\"] = len(abstract_line_split) - 1 # how many total lines are in the abstract? (start from 0)\n",
        "        abstract_samples.append(line_data) # add line data to abstract samples list\n",
        "\n",
        "    else: # if the above conditions aren't fulfilled, the line contains a labelled sentence\n",
        "      abstract_lines += line\n",
        "\n",
        "  return abstract_samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ak4QCUpPlrXe"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "train_samples=preprocess_text_with_line_numbers(data_dir+\"train.txt\")\n",
        "val_samples=preprocess_text_with_line_numbers(data_dir+\"dev.txt\")\n",
        "test_samples=preprocess_text_with_line_numbers(data_dir+\"test.txt\")\n",
        "\n",
        "len(train_samples),len(val_samples),len(test_samples)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QM7H3baXppPj"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "train_df=pd.DataFrame(train_samples)\n",
        "val_df=pd.DataFrame(val_samples)\n",
        "test_df=pd.DataFrame(test_samples)\n",
        "train_df.head(14)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8w9zZObMrzBP"
      },
      "outputs": [],
      "source": [
        "train_sentences=train_df.text.to_list()\n",
        "val_sentences=val_df.text.to_list()\n",
        "test_sentences=test_df.text.to_list()\n",
        "len(train_sentences),len(val_sentences),len(test_sentences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KXDqmnhGsCTL"
      },
      "outputs": [],
      "source": [
        "#One hot encode labels\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "one_hot_encoder=OneHotEncoder(sparse_output=False)\n",
        "train_labels_one_hot=one_hot_encoder.fit_transform(train_df.target.to_numpy().reshape(-1,1))\n",
        "val_labels_one_hot=one_hot_encoder.transform(val_df.target.to_numpy().reshape(-1,1))\n",
        "test_labels_one_hot=one_hot_encoder.transform(test_df.target.to_numpy().reshape(-1,1))\n",
        "train_labels_one_hot.shape,val_labels_one_hot.shape,test_labels_one_hot.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sj--HU5ZphAA"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "train_lines_numbers_one_hot=tf.one_hot(train_df.line_number,depth=15)\n",
        "train_total_lines_one_hot=tf.one_hot(train_df.total_lines,depth=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kjQRv1Rmvo4I"
      },
      "outputs": [],
      "source": [
        "#Extract labels (\"target\" columns) and encode them into numbers\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "label_encoder=LabelEncoder()\n",
        "train_labels=label_encoder.fit_transform(train_df.target)\n",
        "val_labels=label_encoder.transform(val_df.target)\n",
        "test_labels=label_encoder.transform(test_df.target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yQvLdlHAwDnb"
      },
      "outputs": [],
      "source": [
        "num_classes=len(label_encoder.classes_)\n",
        "class_names=label_encoder.classes_\n",
        "num_classes,class_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R3vBJimEuh85"
      },
      "outputs": [],
      "source": [
        "train_sentences_10_percent=train_sentences[:int(len(train_sentences)*0.1)]\n",
        "train_labels_10_percent=train_labels[:int(len(train_labels)*0.1)]\n",
        "train_lines_numbers_10_percent=train_lines_numbers_one_hot[:int(len(train_lines_numbers_one_hot)*0.1)]\n",
        "train_total_lines_10_percent=train_total_lines_one_hot[:int(len(train_total_lines_one_hot)*0.1)]\n",
        "len(train_sentences_10_percent),len(train_labels_10_percent),len(train_lines_numbers_10_percent),len(train_total_lines_10_percent)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p_taXbTbpxgL"
      },
      "outputs": [],
      "source": [
        "# creating a dict with text,label,line_number and total lines\n",
        "dataset=dict()\n",
        "dataset[\"text\"]=train_sentences_10_percent\n",
        "dataset[\"label\"]=train_labels_10_percent\n",
        "dataset[\"lines_numbers\"]=train_lines_numbers_10_percent\n",
        "dataset[\"total_lines\"]=train_total_lines_10_percent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9l7sHIlbqKxI"
      },
      "outputs": [],
      "source": [
        "# converting the dict into datasets with test split 0.2\n",
        "from datasets import Dataset\n",
        "dataset=Dataset.from_dict(dataset)\n",
        "dataset=dataset.train_test_split(test_size=0.2,shuffle=False)\n",
        "dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JV8g_dvrhvMS"
      },
      "source": [
        "# Tokenizing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Semo5oDxqR4H"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "tokenizer=AutoTokenizer.from_pretrained(pretrained_model_name_or_path=\"distilbert/distilbert-base-uncased\",\n",
        "                                        use_fast=True)\n",
        "tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HRzXIIwoqRxp"
      },
      "outputs": [],
      "source": [
        "def tokenize_text(examples):\n",
        "  \"\"\"\n",
        "  Tokenize given example text and return the tokenized text.\n",
        "  \"\"\"\n",
        "  return tokenizer(examples[\"text\"],\n",
        "                   padding=True,\n",
        "                   truncation=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GXvdLY1JqdVL"
      },
      "outputs": [],
      "source": [
        "# map our tokenize function to the dataset\n",
        "tokenized_dataset=dataset.map(function=tokenize_text,\n",
        "                              batched=True,\n",
        "                              batch_size=1000)\n",
        "tokenized_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T13wIWw5qicF"
      },
      "outputs": [],
      "source": [
        "# Lets visulize the tokenized dataset text\n",
        "import random\n",
        "random=random.randint(0,len(tokenized_dataset[\"train\"]))\n",
        "train_data_sample=tokenized_dataset['train'][12]\n",
        "for key in train_data_sample.keys():\n",
        "  print(f\" {key} : {train_data_sample[key]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0lm2lvqY0SqH"
      },
      "outputs": [],
      "source": [
        "import evaluate\n",
        "from typing import Tuple\n",
        "import numpy as np\n",
        "\n",
        "evaluate_metrics=evaluate.load(\"accuracy\")\n",
        "def evaluate_matrics(predictions_labels: Tuple[np.array,np.array]):\n",
        "   predictions,labels=predictions_labels\n",
        "   if(len(predictions.shape)>=2):\n",
        "    predictions=np.argmax(predictions,axis=1)\n",
        "\n",
        "   return evaluate_metrics.compute(predictions=predictions, references=labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8CI5-iNY0_mS"
      },
      "outputs": [],
      "source": [
        "# create a dict id2label for classnames and label2id\n",
        "id2label={idx:label for idx,label in enumerate(class_names)}\n",
        "label2id={label:idx for idx, label in id2label.items()}\n",
        "id2label,label2id"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ycP7PHenj1WR"
      },
      "source": [
        "# Build the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jeEHLY4H0Z25"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "# Setup model for fine-tuning with classification head(top layers of network)\n",
        "\n",
        "model=AutoModelForSequenceClassification.from_pretrained(\n",
        "    pretrained_model_name_or_path=\"distilbert/distilbert-base-uncased\",\n",
        "    num_labels=5,\n",
        "    id2label=id2label,\n",
        "    label2id=label2id\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-jjjvvpG22AP"
      },
      "outputs": [],
      "source": [
        "# Inspect the model\n",
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ib4zTLf73EIL"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "# create a directory\n",
        "models_dir=Path(\"models\")\n",
        "models_dir.mkdir(exist_ok=True)\n",
        "\n",
        "# create a model save name\n",
        "model_save_name=\"SkimLit_Med\"\n",
        "\n",
        "# create model save path\n",
        "model_save_dir=Path(models_dir,model_save_name)\n",
        "\n",
        "model_save_dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qWezLG8P3SX6"
      },
      "outputs": [],
      "source": [
        "from transformers import TrainingArguments\n",
        "\n",
        "training_args=TrainingArguments(\n",
        "    output_dir=model_save_dir,\n",
        "    eval_strategy=\"epoch\",\n",
        "    per_device_train_batch_size=32,\n",
        "    per_device_eval_batch_size=32,\n",
        "    learning_rate=0.0001,\n",
        "    num_train_epochs=3,\n",
        "    save_strategy=\"epoch\",\n",
        "    save_total_limit=3,\n",
        "    use_cpu=False,\n",
        "    seed=42,\n",
        "    load_best_model_at_end=True,\n",
        "    logging_strategy=\"epoch\",\n",
        "    report_to=\"none\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z4Cy1oAr3V21"
      },
      "outputs": [],
      "source": [
        "from transformers import Trainer\n",
        "\n",
        "#Setup Trainer\n",
        "trainer=Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_dataset[\"train\"],\n",
        "    eval_dataset=tokenized_dataset[\"test\"],\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=evaluate_matrics\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "ba6onwKY3abt"
      },
      "outputs": [],
      "source": [
        "results=trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0jDUF0tPj9Zq"
      },
      "outputs": [],
      "source": [
        "# Inspect trainig metrics\n",
        "for key,value in results.metrics.items():\n",
        "  print(f\"{key}:{value}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ugTQsLKQioh2"
      },
      "outputs": [],
      "source": [
        "# Save the model\n",
        "trainer.save_model(output_dir=model_save_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5spjHwUjHbdj"
      },
      "outputs": [],
      "source": [
        "# Get training history\n",
        "trainer_history_all=trainer.state.log_history\n",
        "trainer_history_metrics=trainer_history_all[:-1]\n",
        "training_history_training_time=trainer_history_all[-1]\n",
        "\n",
        "trainer_history_metrics[:4]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EwkG5ujzK6m2"
      },
      "outputs": [],
      "source": [
        "import pprint\n",
        "\n",
        "trainer_history_training_set=[]\n",
        "trainer_history_eval_set=[]\n",
        "\n",
        "for item in trainer_history_metrics:\n",
        "  item_keys=list(item.keys())\n",
        "  if any(\"eval\" in item for item in item_keys):\n",
        "    trainer_history_eval_set.append(item)\n",
        "  else:\n",
        "    trainer_history_training_set.append(item)\n",
        "\n",
        "# Show the first two items in each metric set\n",
        "pprint.pprint(trainer_history_training_set[:3])\n",
        "pprint.pprint(trainer_history_eval_set[:3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q1rt6B4tQpvs"
      },
      "outputs": [],
      "source": [
        "# create pandas dataframe for the training and evaluation metrics\n",
        "trainer_history_training_df=pd.DataFrame(trainer_history_training_set)\n",
        "trainer_history_eval_df=pd.DataFrame(trainer_history_eval_set)\n",
        "\n",
        "trainer_history_training_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QP91-W4iSRG-"
      },
      "outputs": [],
      "source": [
        "# Plot training and evaluate loss\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.plot(trainer_history_eval_df[\"epoch\"],trainer_history_eval_df[\"eval_loss\"],label=\"Evaluation loss\")\n",
        "plt.plot(trainer_history_training_df[\"epoch\"],trainer_history_training_df[\"loss\"],label=\"Training loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.title(\"Text classification with DistilBert training and evaluation loss over time\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VdBfsFhRTTMh"
      },
      "outputs": [],
      "source": [
        "# Save our model to Hugging face hub\n",
        "model_upload_url=trainer.push_to_hub(\n",
        "\n",
        "    commit_message=\"Uploading skimed sentence classifier model\"\n",
        "\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wFwvxLpbxZ-R"
      },
      "outputs": [],
      "source": [
        "model_upload_url"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gszV24tgxhKW"
      },
      "outputs": [],
      "source": [
        "predictions_all=trainer.predict(tokenized_dataset['test'])\n",
        "prediction_values=predictions_all.predictions\n",
        "prediction_metrics=predictions_all.metrics\n",
        "prediction_metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ADx1flIgbwIy"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# 1.Calculate the prediction probability\n",
        "pred_probs=torch.softmax(torch.tensor(prediction_values),dim=1)\n",
        "\n",
        "# 2. Get the predicted labels\n",
        "pred_labels=torch.argmax(pred_probs,dim=1)\n",
        "\n",
        "# 3.Get the true labels\n",
        "true_labels=dataset['test']['label']\n",
        "\n",
        "# 4. Copare prediced labels to true labels\n",
        "test_accuracy=accuracy_score(y_true=true_labels,\n",
        "                             y_pred=pred_labels)\n",
        "\n",
        "print(f\"accuracy :{test_accuracy*100}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EgzXJUl9x5Gv"
      },
      "outputs": [],
      "source": [
        "# Make a DataFrame of test predictions\n",
        "test_predictions_df=pd.DataFrame({\n",
        "    \"text\":dataset[\"test\"][\"text\"],\n",
        "    \"true_labels\":true_labels,\n",
        "    \"pred_label\":pred_labels,\n",
        "    \"pred_prob\":torch.max(pred_probs,dim=1).values\n",
        "})\n",
        "\n",
        "test_predictions_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aCpG15Dh6Wg_"
      },
      "outputs": [],
      "source": [
        "# Show 10 examples with low prediction probabiity\n",
        "test_predictions_df.sort_values(\"pred_prob\",ascending=True).head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zO745Saj946S"
      },
      "outputs": [],
      "source": [
        "# setup local model path\n",
        "huggingface_model_path=\"gokulan006/SkimLit_Med\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kIahkX5uCThx"
      },
      "outputs": [],
      "source": [
        "def set_device():\n",
        "  \"\"\"\n",
        "  Set device to CUDA if available,else MPS(Mac),else CPU.\n",
        "\n",
        "  This defaults to using the best available device(usually).\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  if torch.cuda.is_available():\n",
        "    device=torch.device(\"cuda\")\n",
        "  elif torch.backends.mps.is_available() and torch.backends.mps.is_built():\n",
        "    device=torch.device(\"mps\")\n",
        "  else:\n",
        "    device=torch.device(\"cpu\")\n",
        "  return device\n",
        "\n",
        "\n",
        "DEVICE=set_device()\n",
        "print(DEVICE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ekUQXGyTDzm2"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import pipeline\n",
        "\n",
        "BATCH_SIZE=32\n",
        "\n",
        "SkimLit_Med=pipeline(task=\"text-classification\",\n",
        "                                  model=huggingface_model_path,\n",
        "                                  device=DEVICE,\n",
        "                                  top_k=1,\n",
        "                                  batch_size=BATCH_SIZE)\n",
        "\n",
        "SkimLit_Med"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ONnywVNm0kQz"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "# Ensure you have the required NLTK tokenizer\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "# Input abstract\n",
        "abstract = \"\"\"Home Health Pilot Decreases Readmissions in High Risk Ileostomy PatientsReadmissions to the hospital have come under scrutiny in a new healthcare era. At our institution UHC all-cause 30-day readmission for ileostomies ranged from 15 to 33% (mean 18%). Because ileostomy patients are a high-risk group for readmission, they are an ideal cohort for improvement. The purpose of this pilot was to develop a partnership with a home health agency VNHS in the form of standardized discharge/home health orders that included triggers that would elicit communication back to the surgeon so that a corrective action could be taken before the patient required a readmission. Our goal was to reduce UHC all-cause 30-day readmission in ileostomy patients by 15% (from 18 to 15.3%) in 5 months. The standard order set was vetted and agreed upon by all the stakeholders and implemented. A weekly 15-minute conversation was implemented between the EUH team and VNHS. Because it appeared to be a successful intervention, it was extended to a full year. The readmission rate for VNHS ileostomy patients decreased from 19 to 7%. During the same time, non-VNHS ileostomy patients were receiving standard of care and their readmission rate remained stable, 16 to 20%. Before implementation, VNHS and non-VNHS ileostomy patients had similar readmission rates, 19% and 16%, respectively. During the study period, the total sum cost of readmissions for non-VNHS patients receiving standard of care increased by 58.3%. For patients in the pilot, the readmission costs decreased by 77.6%. In conclusion, we successfully implemented a pilot program that formed a partnership with a home health agency with standardized discharge orders and decreased ileostomy UHC all-cause 30-day readmissions. The pilot was started with a small number of patients, but will be expanded based on this initial success.\"\"\"\n",
        "\n",
        "# Tokenize the abstract into sentences\n",
        "sentences = sent_tokenize(abstract)\n",
        "\n",
        "# Print each sentence (you can replace this with model inference)\n",
        "for idx, sentence in enumerate(sentences):\n",
        "    print(f\"Sentence {idx+1}: {sentence}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C-R2HW_f11Hh"
      },
      "outputs": [],
      "source": [
        "# Test the trained model on sentences\n",
        "SkimLit_Med(sentences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YIvrwW2F3vUH"
      },
      "outputs": [],
      "source": [
        "predicted_labels=[prediction[0][\"label\"] for prediction in SkimLit_Med(sentences)]\n",
        "predicted_labels\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EFMfJ0LYEKW8"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "demos_dir=Path(\"../demos\")\n",
        "demos_dir.mkdir(exist_ok=True)\n",
        "\n",
        "SkimLit_Med_demo_dir=Path(demos_dir,\"SkimLit\")\n",
        "SkimLit_Med_demo_dir.mkdir(exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tY67w5AaEteX"
      },
      "outputs": [],
      "source": [
        "%%writefile ../demos/SkimLit/app.py\n",
        "import torch\n",
        "import gradio as gr\n",
        "import nltk\n",
        "from typing import Dict, List\n",
        "from transformers import pipeline\n",
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "\n",
        "nltk.download('punkt')\n",
        "\n",
        "\n",
        "def skimMed(text: str) -> str:\n",
        "    \"\"\"\n",
        "    Takes an input abstract text and classifies it into sections like\n",
        "    'OBJECTIVE', 'METHODS', 'RESULTS', 'CONCLUSIONS', and 'BACKGROUND'.\n",
        "    \"\"\"\n",
        "\n",
        "    # Load Hugging Face model\n",
        "    SkimLit_Med = pipeline(\n",
        "        task=\"text-classification\",\n",
        "        model=\"gokulan006/SkimLit_Med\",\n",
        "        batch_size=32,\n",
        "        device=0 if torch.cuda.is_available() else -1,\n",
        "        top_k=None\n",
        "    )\n",
        "\n",
        "    # Tokenize the abstract into sentences\n",
        "    sentences = sent_tokenize(text)\n",
        "\n",
        "    # Predicted labels for each sentence\n",
        "    predicted_labels = [prediction[0][\"label\"] for prediction in SkimLit_Med(sentences)]\n",
        "\n",
        "    # Creating a dictionary to store text based on section labels\n",
        "    sections = {label: [] for label in [ \"BACKGROUND\",\"OBJECTIVE\", \"METHODS\", \"RESULTS\", \"CONCLUSIONS\"]}\n",
        "\n",
        "    # Map each abstract line to its predicted label\n",
        "    for line, label in zip(sentences, predicted_labels):\n",
        "        sections[label].append(line)\n",
        "\n",
        "\n",
        "    ordered_abstract = \"\\n\\n\".join([f\"{key}:\\n\" + \"\\n\".join(sections[key]) for key in sections if sections[key]])\n",
        "\n",
        "    return ordered_abstract\n",
        "\n",
        "# 3. Create a Gradio interface\n",
        "description = \"\"\"\n",
        "Medical Abstract Skimmer Automatically Organize Medical Abstracts into Structured Sections (Objective, Methods, Results, Conclusions, Background).\n",
        "\n",
        "Fine-tuned from [DistilBERT](https://huggingface.co/distilbert/distilbert-base-uncased) on a [PubMed 20k RCT Dataset](https://github.com/Franck-Dernoncourt/pubmed-rct/tree/master/PubMed_20k_RCT).\n",
        "\"\"\"\n",
        "\n",
        "demo = gr.Interface(\n",
        "    fn=skimMed,\n",
        "    inputs=gr.Textbox(lines=10, placeholder=\"Enter your medical abstract here...\", label=\"Enter Medical Abstract\"),\n",
        "    outputs=gr.Textbox(label=\"Formatted Medical Abstract\"),\n",
        "    title=\"ðŸ“šðŸ©º Medical Abstract Skimmer ðŸ©ºðŸ“š\",\n",
        "    description=description,\n",
        "    theme=\"soft\",\n",
        "    examples=[\n",
        "        [\"Telemedicine has emerged as a promising solution to address healthcare access issues in rural populations, particularly for patients with chronic diseases. This study aimed to evaluate the effectiveness of telemedicine in managing chronic conditions in rural areas. We conducted a randomized controlled trial with 200 participants diagnosed with hypertension or diabetes in rural areas. Participants were randomly assigned to either a telemedicine group or a usual care group. The telemedicine group received remote consultations, medication management, and monitoring through digital health platforms, while the usual care group continued standard in-person visits. Both groups were followed for six months. The telemedicine group showed a significant improvement in blood pressure control (mean decrease of 15 mmHg) and blood sugar levels (mean decrease of 1.5% in HbA1c) compared to the usual care group, where the improvements were 5 mmHg and 0.5% in HbA1c, respectively. Additionally, the telemedicine group reported higher satisfaction levels and fewer hospital visits than the usual care group. Telemedicine proved to be an effective and acceptable approach for managing chronic diseases in rural populations, demonstrating improvements in both clinical outcomes and patient satisfaction. The findings support the broader implementation of telemedicine in rural healthcare settings.\"]\n",
        "    ],\n",
        "    allow_flagging=\"never\"\n",
        ")\n",
        "\n",
        "# 4. Launch the interface\n",
        "if __name__ == \"__main__\":\n",
        "    demo.launch()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IP62aTfRHptW"
      },
      "outputs": [],
      "source": [
        "%%writefile ../demos/SkimLit/requirements.txt\n",
        "gradio\n",
        "torch\n",
        "transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4UVZGyXkH2e4"
      },
      "outputs": [],
      "source": [
        "%%writefile ../demos/SkimLit/README.md\n",
        "---\n",
        "title: Medical Abstract Skimmer\n",
        "emoji:  ðŸ“šðŸ©º\n",
        "colorFrom: blue\n",
        "colorTo: yellow\n",
        "sdk: gradio\n",
        "app_file: app.py\n",
        "pinned: false\n",
        "license: apache-2.0\n",
        "---\n",
        "\n",
        "#  SkimLit_med\n",
        "\n",
        "Medical Abstract Skimmer Automatically Organize Medical Abstracts into Structured Sections (Objective, Methods, Results, Conclusions, Background)\n",
        "\n",
        "Fine-tuned from [DistilBERT](https://huggingface.co/distilbert/distilbert-base-uncased) on a [PubMed 20k RCT Dataset](https://github.com/Franck-Dernoncourt/pubmed-rct/tree/master/PubMed_20k_RCT).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XddV-j6eIS2p"
      },
      "outputs": [],
      "source": [
        "!ls ../demos/SkimLit/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aiYZ7DM0IZJ8"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import (\n",
        "    create_repo,\n",
        "    get_full_repo_name,\n",
        "    upload_file,\n",
        "    upload_folder\n",
        ")\n",
        "\n",
        "\n",
        "LOCAL_DEMO_FOLDER_PATH_TO_UPLOAD = \"../demos/SkimLit\"\n",
        "HF_TARGET_SPACE_NAME = \"SkimLit\"\n",
        "HF_REPO_TYPE = \"space\"\n",
        "HF_SPACE_SDK = \"gradio\"\n",
        "\n",
        "# 3. Create a Space repository on Hugging Face Hub\n",
        "print(f\"[INFO] Creating repo on Hugging Face Hub with name: {HF_TARGET_SPACE_NAME}\")\n",
        "\n",
        "\n",
        "\n",
        "full_hf_repo_name = get_full_repo_name(model_id=HF_TARGET_SPACE_NAME)\n",
        "print(f\"[INFO] Full Hugging Face Hub repo name: {full_hf_repo_name}\")\n",
        "\n",
        "#  Upload our demo folder\n",
        "print(f\"[INFO] Uploading {LOCAL_DEMO_FOLDER_PATH_TO_UPLOAD} to repo: {full_hf_repo_name}\")\n",
        "folder_upload_url = upload_folder(\n",
        "    repo_id=\"gokulan006/SkimLit\",\n",
        "    folder_path=LOCAL_DEMO_FOLDER_PATH_TO_UPLOAD,\n",
        "    path_in_repo=\".\",\n",
        "\n",
        "    repo_type=HF_REPO_TYPE,\n",
        "    commit_message=\"Uploading SkimLit demo app.py\"\n",
        ")\n",
        "print(f\"[INFO] Demo folder successfully uploaded with commit URL: {folder_upload_url}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
